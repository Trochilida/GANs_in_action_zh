# 第10章对抗性样本

### 本章涵盖

- GAN之前的研究领域和交织的历史
- 计算机视觉中的深度学习方法

- 我们自己的具有真实图像和噪音的对抗示例

在本书的学习过程中，您已经将GAN理解为一个明确的概念。但是，在2014年，GAN似乎上是一次质的飞跃，尤其是对于那些不熟悉新兴的对抗性领域的人来说，包括Ian Goodfellow等人在该领域的工作[^1]。本章将深入研究对抗性样本(Adversarial examples)，这些样本是特殊构造的样本，这些样本使其他分类算法发生灾难性的失效。”

我们还讨论了他们与GAN的联系，以及为何对抗性学习(adversarial learning)仍然是机器学习中一个尚未解决的问题--这是当前方法的一个重要但很少讨论的缺陷。包括对抗性样本在机器学习的鲁棒性，公平性和安全性中起着重要作用

不可否认，在过去五年中，机器学习的能力正在匹及并超越人类水平,其性能方面取得了长足进步，例如在计算机视觉（CV）分类任务或玩游戏的能力上[^ 2]。但是，仅查看指标和ROC曲线[^ 3]不足以让我们理解:（a）神经网络为何做出决策（工作方式）以及（b）神经网络容易出错。本章涉及第一章，然后深入到第二章。在开始之前，应该说，尽管本章几乎只涉及计算机视觉的问题，但在诸如文本甚至人类的各个领域都已经发现了对抗性样本[^ 4]。

首先，当我们谈论神经网络的性能时，我们经常读到它们在大型数据集ImageNet上的分类错误率低于人类。这是经常被引用的统计数据（比起其他任何事情都更像是一个学术笑话），其掩盖了在平均值下方隐藏的绩效差异。尽管人类的错误通常主要是由于他们无法区分在此数据集中突出显示的不同品种的狗而引起的，但机器学习失败的情况却不祥得多。经过进一步调查，出现了一些对抗性例子。

与人类不同，CV算法要解决的问题在本质上非常不同并且是与训练数据有关的问题。因为该算法必须对每张图片进行预测，所以即使我们有很多实例，也必须通过训练数据中看到的孤立和遥远的个体实例之间进行推断。

当我们训练了诸如Inception V3和VGG-19之类的网络时，我们发现了一种使图像分类器在训练数据的细流形(thin manifold)上工作的惊人方法。但是，当人们试图戳破这些算法的分类能力时，他们发现了一个宇宙级大坑-当前的机器学习算法很容易被甚至很小的扭曲所愚弄。迄今为止，几乎所有成功的主要机器学习算法都在一定程度上遭受了该缺陷的影响，并且确实有人推测这就是为什么机器学习起作用的原因。

NOTE：在有监督的情况下，思考我们的训练集。我们有一个训练流形-描述了样本所在高维度的分布。例如，我们的300×300像素图像存在与在270,000维空间（300×300×3color）中。这使得训练非常复杂。



#### 10.1. 对抗性样本的上下文

首先，我们想快速讲解为什么在本书结尾处包含本章：

- 通过对抗性样本，我们通常试图生成新的样本，这些样本会使我们现有的系统被蒙蔽，从而错误地分类。我们通常以邪恶的攻击者的身份或以研究人员的身份这样做，以了解我们的系统将如何强大地运行。尽管存在重大差异，但对抗性示例与GAN密切相关。
- 这将使您了解为什么GAN可能很难训练，以及为什么我们现有的系统如此脆弱。
- 对抗性示例允许GAN使用不同的应用程序集合，我们希望至少为您提供其功能的基础知识。

就应用而言，对抗性样本很有趣，原因有以下几个：

- 正如所讨论的，对抗性示例可以用于恶意目的，因此测试关键系统的鲁棒性非常重要。如果攻击者可以轻易地愚弄面部识别系统来访问您的手机怎么办？
- 它们帮助我们了解机器学习的公平性-这是一个日益重要的主题。我们可以使用对抗性学习的表示形式，这些表示形式对于分类很有用，但不允许攻击者恢复受保护的事实，这可能是确保我们的ML不歧视任何人的最佳方法之一。
- 同样，我们可以使用对抗性学习来保护有关个人的敏感信息（可能是医疗或财务信息）的隐私。在这种情况下，我们仅关注与无法恢复的个人有关的信息。”

按照当前的研究现状，了解对抗性示例是开始理解对抗性防御的唯一方法，因为大多数论文都首先描述了其防御的攻击类型，然后才尝试解决它们。在撰写本书时，没有针对所有类型攻击的通用防御措施。但是，这是否是研究它们的好理由，取决于您对对抗示例的看法。我们决定不详细介绍防御措施-在本章末尾的高级思想之上-因为超出此范围的所有内容均不包括在内。

[^1]:See “Intriguing Properties of Neural Networks,” by Christian Szegedy et al., 2014, https://arxiv.org/pdf/1312.6199.pdf

[^2]: What constitutes human-level performance in vision-classification tasks is a complicated topic. However, at least in, for example, Dota 2 and Go, AI has beat human experts by a substantial margin.
[^3]:A receiver operating characteristic (ROC) curve explains the trade-offs between false positives and negatives. We also encountered them in chapter 2. For more details, Wikipedia has an excellent explanation.
[^4]:See “Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey,” by Wei Emma Zhang et al., 2019, http://arxiv.org/abs/1901.06796. See also “Adversarial Examples That Fool Both Computer Vision and Time-Limited Humans,” by Gamaleldin F. Elsayed et al., 2018, http://arxiv.org/abs/1802.08195.









